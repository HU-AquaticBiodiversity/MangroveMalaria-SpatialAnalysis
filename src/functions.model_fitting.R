# ==============================================================================
# SPATIAL SEM OPTIMIZATION ENGINE (Source Functions)
# Description: Contains the core functions to prep data, dynamically update SEM 
# formulas based on d-separation and p-values, and run parallelised iterations.
# ==============================================================================

## -----------------------------------------------------------------------------
## 1. DATA PREPARATION FUNCTION
## -----------------------------------------------------------------------------
data.prep <- function(x) {
  rename(x, mean_ndvi = mean.ndvi, mangrove_cover = mangrove.cover) %>%
    mutate(
      # Calculate raw infected count and true prevalence proportion
      infected = round(pr * examined, 0),
      pr.new = infected / examined,
      
      # Non-linear (quadratic) weather transformations (scaled for convergence)
      anomaly_2t_sqr = scale(anomaly_2t^2), 
      anomaly_tp_sqr = scale(anomaly_tp^2),
      mean_2t_sqr = scale(mean_2t^2), 
      mean_tp_sqr = scale(mean_tp^2), 
      anomaly_2t_6m_sqr = scale(anomaly_2t_6m^2),
      anomaly_tp_6m_sqr = scale(anomaly_tp_6m^2),
      mean_2t_6m_sqr = scale(mean_2t_6m^2), 
      mean_tp_6m_sqr = scale(mean_tp_6m^2), 
      
      # Grouping variable for Random Effects & Spatial Autocorrelation
      group = factor(paste0(year_start, month_start, method))
    )
}



## -----------------------------------------------------------------------------
## 2. MODEL FITTING FUNCTION (Runs 1-50km Radii)
## -----------------------------------------------------------------------------
# input_data: Dataset to use
# input_formula: The starting formulas (or outputs from previous optimization step)
# ptd / pta: "Paths to Drop" and "Paths to Add" generated by previous step
# ------------------------------------------------------------------------------
model_fit <- function(input_data, input_formula, ptd, pta) {
  
  dep <- c("pr.new", "mean_ndvi", "mangrove_cover")
  
  # A. Dynamically construct the formula for this specific step
  f <- lapply(1:3, function(s) {
    
    # Check if there are Paths to Drop (ptd) for this dependent variable
    if(nrow(filter(ptd, dependent == dep[s])) == 0) {
      ptd.f <- NA
    } else {
      # Create a string like "- var1 - var2"
      ptd.f <- ptd %>% filter(dependent == dep[s]) %>% pull("independent")
      ptd.f <- paste0("- ", paste(ptd.f, collapse = " - "))
    }
    
    # Check if there are Paths to Add (pta) for this dependent variable
    if(nrow(filter(pta, dependent == dep[s])) == 0) {
      pta.f <- NA
    } else {
      # Create a string like "+ var1 + var2"
      pta.f <- pta %>% filter(dependent == dep[s]) %>% pull("independent")
      pta.f <- paste0("+ ", paste(pta.f, collapse = " + "))
    }
    
    # Update the baseline formula with the drops and adds
    update(input_formula[[s]], paste0(na.omit(c("~.", ptd.f, pta.f)), collapse = ""))
  })
  
  # B. Parallel Execution across 50 spatial radii
  res <- mclapply(1:50, function(r) {
    
    # Filter data to specific spatial buffer
    input_set <- input_data %>% filter(buffer == r)
    
    # Model A: Prevalence (Binomial)
    model.pr.1 <- glmmPQL(
      fixed = as.formula(paste(deparse(f[[1]]), collapse ="")),
      random = ~ 1 | group,
      correlation = corExp(1, form = ~ lat + lon | group, nugget = TRUE),
      data = input_set,
      weights = input_set$examined,
      control = lmeControl(msMaxIter = 1000, msMaxEval = 1000),
      family = binomial(link = "logit"),
      verbose = FALSE
    )
    
    # Model B: NDVI (Gaussian)
    model.vi.1 <- update(model.pr.1, as.formula(paste(deparse(f[[2]]), collapse ="")), family = gaussian)
    
    # Model C: Mangrove Cover (Gaussian)
    model.mc.1 <- update(model.vi.1, as.formula(paste(deparse(f[[3]]), collapse ="")))
    
    # Construct Piecewise SEM
    mangrove_sem <- psem(model.pr.1, model.vi.1, model.mc.1, data = input_set)
    
    # Extract key SEM validation statistics
    a <- list(
      plot(mangrove_sem, return = TRUE), 
      dSep(mangrove_sem, .progressBar = FALSE), # Tests for missing paths
      fisherC(mangrove_sem),                    # Overall model fit
      coefs(mangrove_sem),                      # Path coefficients
      AIC_psem(mangrove_sem)
    )
    
    print(paste0(r, "/50 Done!"))
    return(a)
    
  }, mc.preschedule = FALSE, mc.cores = numberOfCores)
  
  # Return both the new formulas used and the raw SEM results
  list(f, res)
}

## -----------------------------------------------------------------------------
## 3. MODEL INTERPRETATION (Extracts Paths to Drop/Add)
## -----------------------------------------------------------------------------
model_interpretation <- function(sem_model) {
  
  # Extract Fisher's C overall model fit (Keep models where P > 0.05, meaning good fit)
  f_test <- pblapply(1:50, function(x) {
    if(!inherits(sem_model[[x]], "try-error")) {
      unlist(c(sem_model[[x]][[3]], buffer = x))
    }
  }) %>% 
    bind_rows() %>%
    filter(P.Value > .05)
  
  # PATHS TO DROP: Find relationships that are consistently non-significant
  # (Value 1.00 means no model supports the relationship at any radius)
  paths_to_drop <- pblapply(f_test$buffer, function(x) {
    if(!inherits(sem_model[[x]], "try-error")) {
      sem_model[[x]][[4]][, 1:8] %>%
        filter(P.Value > 0.05) %>%
        unite('paths', c(Response, Predictor), sep = '-') %>%
        pull(paths)
    }
  })
  
  # PATHS TO ADD: Find missing links flagged by d-separation
  paths_to_add <- pblapply(f_test$buffer, function(x) {
    if(!inherits(sem_model[[x]], "try-error")) {
      sem_model[[x]][[2]][, 1:5] %>%
        filter(P.Value < 0.05) %>% # d-sep flagged as significant (needs adding)
        pull(Independ.Claim)
    }
  })
  
  # Output proportions (Frequency of path being dropped/added across all valid radii)
  output <- list(
    "F_Test" = f_test, 
    "paths_to_drop" = table(unlist(paths_to_drop)) / nrow(f_test),
    "paths_to_add" = table(unlist(paths_to_add)) / nrow(f_test)
  )
  return(output)
}

## -----------------------------------------------------------------------------
## 4. OPTIMIZATION DATA EXPORT (Saves pta/ptd to CSV)
## -----------------------------------------------------------------------------
model_optim_info <- function(sem_results, name) {
  
  ptd.table <- data.frame(model_interpretation(sem_results)$paths_to_drop)
  
  # If any paths need dropping (Freq == 1 means 100% of models say drop it)
  if(nrow(ptd.table) > 0) {
    ptd <- ptd.table %>%
      separate(col = Var1, c("dependent", "independent"), sep = "-") %>%
      filter(Freq == 1) 
    write.table(ptd, file = paste0("./data/", name,"_ptd.csv"), sep = ",", row.names = FALSE)
  }
  
  pta.table <- data.frame(model_interpretation(sem_results)$paths_to_add)
  
  # If any paths need adding (Freq >= 0.1 means at least 10% of models say add it)
  if(nrow(pta.table) > 0) {
    pta <- pta.table %>%
      separate(col = Var1, c("dependent", "x", "independent", "y", "z"), sep = " ") %>%
      dplyr::select(-x, -y, -z) %>%
      filter(Freq >= .1)
    write.table(pta, file = paste0("./data/", name,"_pta.csv"), sep = ",", row.names = FALSE)
  }
}

## -----------------------------------------------------------------------------
## 5. MAIN MODEL RUNNER (The Step-Wise Controller)
## -----------------------------------------------------------------------------
model.run <- function(step, model.select) {
  
  round.vec <- c(NA, "_small", "_5k", "_20k", "_newvars", "_sqr")[model.select]
  
  lapply(round.vec, function(round) {
    
    # --- A. Load "Paths to Add" (pta) ---
    pta.dir <- paste0(na.omit(c("./data/sem_results_", step, round, "_pta.csv")), collapse = "")
    if(step == 1 | !file.exists(pta.dir)) {
      pta.var <- data.frame(dependent = character(), independent = character(), Freq = numeric())
    } else {
      pta.var <- read.csv(pta.dir) %>%
        filter(independent != "pr.new") # Prevent reverse causality/circularity
    }
    
    # --- B. Load "Paths to Drop" (ptd) ---
    ptd.dir <- paste0(na.omit(c("./data/sem_results_", step, round, "_ptd.csv")), collapse = "")
    if(step == 1 | !file.exists(ptd.dir)) {
      ptd.var <- data.frame(dependent = character(), independent = character(), Freq = numeric())
    } else {
      ptd.var <- read.csv(ptd.dir) %>%
        # CRITICAL PROTECTIONS: Never drop our core biological hypotheses
        filter(!(dependent == "pr.new" & independent == "mangrove_cover")) %>%
        filter(!(dependent == "pr.new" & independent == "mean_ndvi")) %>%
        filter(!(dependent == "mean_ndvi" & independent == "mangrove_cover")) %>%
        filter(!(dependent == "mangrove_cover" & independent == "mangrove.cover.min1"))
    }
    
    # --- C. Execute Optimization Step ---
    # Only run if there are changes to make (or if it is the very first step)
    if(nrow(pta.var) > 0 | nrow(ptd.var) > 0 | step == 1) {
      
      # Generate dynamic variable names for this environment
      model.var <- paste0(na.omit(c("sem_results_", step, round)), collapse ="")
      model.var.next <- paste0(na.omit(c("sem_results_", step + 1, round)), collapse ="")
      
      formula.var <- paste0(na.omit(c("start.formulas_", step, round)), collapse = "")
      formula.var.next <- paste0(na.omit(c("start.formulas_", step + 1, round)), collapse = "")
      
      # Load baseline formulas
      if(step == 1) {
        formula.load <- get(formula.var)
      } else {
        formula.load <- readRDS(paste0("./data/", formula.var, ".rds"))
      }
      
      # Select dataset
      data.var <- ifelse(is.na(round) | round != "_small", "all.data", "all.data.small")
      
      system.time({
        # Run the SEM across all 50 radii
        output <- model_fit(input_data = get(data.var),
                            input_formula = formula.load,
                            pta = pta.var,
                            ptd = ptd.var)
        
        # Save results to dynamically named variables in the environment
        assign(model.var, output[[2]])
        assign(formula.var.next, output[[1]])
      })
      
      # Save final models and updated formulas to disk
      saveRDS(get(model.var), file = paste0("./data/", model.var, ".rds"))
      saveRDS(get(formula.var.next), file = paste0("./data/", formula.var.next, ".rds"))
      
      # Trigger interpretation to prep the csv files for the NEXT step
      model_optim_info(get(model.var), model.var.next)
      
    } else {
      print(paste0("No further optimisation needed for model type ", round, " at step ", step, "."))
    }
  })
}